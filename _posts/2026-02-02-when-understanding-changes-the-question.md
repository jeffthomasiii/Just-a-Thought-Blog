---
layout: post
title: "When Understanding Changes the Question"
subtitle: ""
description: "A personal reflection on how AI tools are reshaping our relationship with understanding, trust, and discernment."
date: 2026-02-02
author: Jeff Thomas III
categories:
  - technology
  - reflection
tags:
  - AI
  - discernment
  - understanding
  - NotebookLM
  - wisdom
excerpt: "AI hasn’t made me smarter, it’s made me more aware of what I don’t understand, and how often I’ve been willing to move forward anyway."
image: /img/posts/when-understanding-changes-the-question.jpg
background: /img/posts/bg-when-understanding-changes-the-question.jpg
---

I remember listening to an AI-generated audio overview of one of my own [blog posts](https://jeffthomasiii.github.io/Just-a-Thought-Blog/faith/tech/2025/07/18/Hearing-My-Words-Out-Loud.html) and stopping halfway through.

My first thought was, *That’s exactly what I was trying to say.*  
My second was, *That’s not what I meant… but it’s an interesting take.*

That moment stayed with me.  
Not because it felt impressive, but because it felt revealing.

For a long time, I’ve accepted a quiet reality most of us don’t like to admit out loud: there are things we agree to, approve, or move past without fully understanding them.

Not because we’re careless.  
But because the material itself feels impenetrable.

Long documents.  
Dense language.  
“Standard terms.”

At some point, trust replaces comprehension.

Lately, that dynamic has cracked open for me.

I’ve been spending time with AI tools that are remarkably good at research, parsing massive documents, summarizing, and, more importantly, *contextualizing* information. Not just telling me what something says but helping me see how it fits together. Where it contradicts itself. Where it quietly assumes things I may not actually agree with.

It’s made me wonder how many decisions in modern life are built on borrowed confidence.

Take contracts, for example.

Imagine uploading a long agreement and asking a few clarifying questions:  
Where is the risk concentrated?  
Which sections are intentionally vague?  
What assumptions does this language make about me?  
Where would someone with a different risk tolerance pause?

That’s a very different posture than, *I have no idea what this says, but they tell me it’s standard language.*

Someone shared a story with me recently that stuck.

They uploaded a massive document into several different AI tools and thought they had a solid grasp of it. Then they ran the same material through another tool designed to stay grounded in the original source.

Their response was blunt: *“Boy was I wrong.”*

It surfaced discrepancies.  
Missed nuances.  
Contextual gaps the others glossed over.

That experience mirrors my own, just in smaller ways.

It doesn’t feel like being replaced.  
It feels like being *reflected*.

Sometimes accurately.  
Sometimes imperfectly.  
Always revealing something about how ideas land once they leave my head.

I’ve even used AI to generate infographics using nothing but a single blog post as the source. No added ideas. No external framing. Just structure pulled from what was already there.

I don’t love everything about the result. Some choices feel off. Some emphasis isn’t how I would have framed it. But seeing my own words reorganized visually, without outside input, was still impressive.

Not because it was perfect, but because it revealed shape.

<figure style="text-align:center; margin:1rem 0;">
  <img 
    src="https://jeffthomasiii.github.io/Just-a-Thought-Blog/img/posts/ai-infographic-single-source.jpg"
    alt="AI-generated infographic created using my Spiritual Sweat post"
    style="width:95%;"
  />
  <figcaption style="font-style:italic; font-size:0.9em; margin-top:0.5rem;">
    An AI-generated infographic created using only my Spiritual Sweat post, imperfect, but revealing how structure emerges when ideas are reorganized.
  </figcaption>
</figure>


At the same time, I’m watching people use these tools in increasingly creative, and sometimes obvious, ways. LinkedIn articles generated for reach. Content pipelines optimized for traffic.

AI doesn’t just surface information.  
It surfaces intention.

And somewhere along the way, the question around AI quietly shifted.

It used to be, *Are you using AI?*  
Now it’s more often, *How are you using it?*  
And maybe even, *Do you trust it?*

That last question matters more than we think.

Because trust isn’t the same as usefulness.  
And assistance isn’t the same as delegation.

These tools are incredibly good at helping us *see*.  
They are poor substitutes for judgment.

They don’t carry values.  
They don’t own consequences.  
They don’t live with outcomes.

They just surface what’s there.

What we do with it still says something about us.

People are already using AI in churches and ministries too, for writing, organization, planning, communication. I have strong thoughts about that space, but they deserve a slower, more careful conversation.

That reflection is coming later, in a series I’m calling *Faith, Wisdom, and the Machine*.

For now, I’m sitting with something simpler.

AI hasn’t made me smarter.  
It’s made me more aware of what I don’t understand, and how often I’ve been willing to move forward anyway.

Maybe the real shift isn’t technological at all.  
Maybe it’s relational.

Between us and information.  
Between confidence and clarity.  
Between speed and discernment.

When understanding changes, the questions we ask change too.

…just a thought.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTg5NTc3OTE5LC0xOTcyMTc2NTc3LDE5Nz
gyNTgxMTMsMTc1MTM1MjA3OSw1MzIyNTM4MjksMTEwOTI0NTE2
Niw0MjAwMDEzNTAsLTExMjU2NzAxNjhdfQ==
-->