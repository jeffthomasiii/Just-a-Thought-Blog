---
layout: post
title: "When Understanding Changes the Question"
subtitle: ""
description: "A personal reflection on how AI tools are reshaping our relationship with understanding, trust, and discernment."
date: 2026-02-02
author: Jeff Thomas III
categories:
  - technology
  - reflection
tags:
  - AI
  - discernment
  - understanding
  - NotebookLM
  - wisdom
excerpt: "AI hasn‚Äôt made me smarter, it‚Äôs made me more aware of what I don‚Äôt understand, and how often I‚Äôve been willing to move forward anyway."
image: /img/posts/when-understanding-changes-the-question.jpg
background: /img/posts/bg-when-understanding-changes-the-question.jpg
---

I remember listening to an AI-generated audio overview of one of my own [blog posts](https://jeffthomasiii.github.io/Just-a-Thought-Blog/faith/tech/2025/07/18/Hearing-My-Words-Out-Loud.html) and stopping halfway through.

My first thought was, *That‚Äôs exactly what I was trying to say.*  
My second was, *That‚Äôs not what I meant‚Ä¶ but it‚Äôs an interesting take.*

That moment stayed with me.  
Not because it felt impressive, but because it felt revealing.

For a long time, I‚Äôve accepted a quiet reality most of us don‚Äôt like to admit out loud: there are things we agree to, approve, or move past without fully understanding them.

Not because we‚Äôre careless.  
But because the material itself feels impenetrable.

Long documents.  
Dense language.  
‚ÄúStandard terms.‚Äù

At some point, trust replaces comprehension.

Lately, that dynamic has cracked open for me.

I‚Äôve been spending time with AI tools that are remarkably good at research, parsing massive documents, summarizing, and, more importantly, *contextualizing* information. Not just telling me what something says but helping me see how it fits together. Where it contradicts itself. Where it quietly assumes things I may not actually agree with.

It‚Äôs made me wonder how many decisions in modern life are built on borrowed confidence.

Take contracts, for example.

Imagine uploading a long agreement and asking a few clarifying questions:  
Where is the risk concentrated?  
Which sections are intentionally vague?  
What assumptions does this language make about me?  
Where would someone with a different risk tolerance pause?

That‚Äôs a very different posture than, *I have no idea what this says, but they tell me it‚Äôs standard language.*

Someone shared a story with me recently that stuck.

They uploaded a massive document into several different AI tools and thought they had a solid grasp of it. Then they ran the same material through another tool designed to stay grounded in the original source.

Their response was blunt: *‚ÄúBoy was I wrong.‚Äù*

It surfaced discrepancies.  
Missed nuances.  
Contextual gaps the others glossed over.

That experience mirrors my own, just in smaller ways.

It doesn‚Äôt feel like being replaced.  
It feels like being *reflected*.

Sometimes accurately.  
Sometimes imperfectly.  
Always revealing something about how ideas land once they leave my head.

I‚Äôve even used AI to generate infographics using nothing but a single blog post as the source. No added ideas. No external framing. Just structure pulled from what was already there.

I don‚Äôt love everything about the result. Some choices feel off. Some emphasis isn‚Äôt how I would have framed it. But seeing my own words reorganized visually, without outside input, was still impressive.

Not because it was perfect, but because it revealed shape.

<!-- üìå IMAGE INSERT POINT: Place infographic directly below this line -->

![AI-generated infographic derived from a single source document](/img/posts/ai-infographic-single-source.jpg)
*Caption: An AI-generated infographic created using only one source document, imperfect, but revealing how structure emerges when ideas are reorganized.*

At the same time, I‚Äôm watching people use these tools in increasingly creative, and sometimes obvious, ways. LinkedIn articles generated for reach. Content pipelines optimized for traffic.

AI doesn‚Äôt just surface information.  
It surfaces intention.

And somewhere along the way, the question around AI quietly shifted.

It used to be, *Are you using AI?*  
Now it‚Äôs more often, *How are you using it?*  
And maybe even, *Do you trust it?*

That last question matters more than we think.

Because trust isn‚Äôt the same as usefulness.  
And assistance isn‚Äôt the same as delegation.

These tools are incredibly good at helping us *see*.  
They are poor substitutes for judgment.

They don‚Äôt carry values.  
They don‚Äôt own consequences.  
They don‚Äôt live with outcomes.

They just surface what‚Äôs there.

What we do with it still says something about us.

People are already using AI in churches and ministries too, for writing, organization, planning, communication. I have strong thoughts about that space, but they deserve a slower, more careful conversation.

That reflection is coming later, in a series I‚Äôm calling *Faith, Wisdom, and the Machine*.

For now, I‚Äôm sitting with something simpler.

AI hasn‚Äôt made me smarter.  
It‚Äôs made me more aware of what I don‚Äôt understand, and how often I‚Äôve been willing to move forward anyway.

Maybe the real shift isn‚Äôt technological at all.  
Maybe it‚Äôs relational.

Between us and information.  
Between confidence and clarity.  
Between speed and discernment.

When understanding changes, the questions we ask change too.

‚Ä¶just a thought.

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEwOTI0NTE2Niw0MjAwMDEzNTAsLTExMj
U2NzAxNjhdfQ==
-->